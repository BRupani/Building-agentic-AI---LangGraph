{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR5sC14itXUV",
        "outputId": "ff4af8e1-3dff-47f7-e77b-c2081c764b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.49)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.70.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.3.22)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (4.13.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.11.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.3.12 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install -U langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY= \"sk-proj-KnrONy6W1s4evIFt\"\n"
      ],
      "metadata": {
        "id": "42rHHEVYtdHb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-KnAJbhwCyArONy6W1s4evIFt\"\n"
      ],
      "metadata": {
        "id": "OyCWOlB0uPeJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "ahbjbrgwvDQ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n"
      ],
      "metadata": {
        "id": "ETZQvUmZvOL0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n"
      ],
      "metadata": {
        "id": "9MMKJJ-GvQnj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.agents import initialize_agent, AgentType, Tool\n"
      ],
      "metadata": {
        "id": "wF3zBqwVvslf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n"
      ],
      "metadata": {
        "id": "x-JQP8dbvtaB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_tool(query: str) -> str:\n",
        "    return f\"Search result for: {query}\"\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=search_tool,\n",
        "        description=\"Useful for answering general questions.\"\n",
        "    )\n",
        "]\n"
      ],
      "metadata": {
        "id": "DGyvSmggvyXJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngsivKwvv2tG",
        "outputId": "18c2c284-f7fe-4570-f13f-453321fe6fbf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2037b19914f3>:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langgraph langchain-openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nqP_5DlwHny",
        "outputId": "37f339b9-d78b-4c64-ba7f-2e808446aae9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.25-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.49)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.70.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.22)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.13.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.11.1)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
            "Downloading langgraph-0.3.25-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m142.4/142.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.25 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 ormsgpack-1.9.1 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n"
      ],
      "metadata": {
        "id": "Mxe3K-C8wDPq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_tool(query: str) -> str:\n",
        "    \"\"\"Search the web for the given query.\"\"\"\n",
        "    # Implement the search functionality here\n",
        "    return f\"Search results for: {query}\"\n"
      ],
      "metadata": {
        "id": "9tgUKq3RwLnd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(model=llm, tools=[search_tool])\n"
      ],
      "metadata": {
        "id": "Bg-x753ywSRw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.invoke({\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Who won the FIFA World Cup in 2022?\"}\n",
        "    ]\n",
        "})\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "626miLf1wU8w",
        "outputId": "8a86f163-13eb-40c3-bdb9-4525d4c0eb9d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Who won the FIFA World Cup in 2022?', additional_kwargs={}, response_metadata={}, id='c9c2e7b9-4e4a-4bb4-a4b8-555e85b78141'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_T6B8oGQRcm5Y964QCKQ9BO4F', 'function': {'arguments': '{\"query\":\"FIFA World Cup 2022 winner\"}', 'name': 'search_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 57, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BIW18i29Hi8H9rkNt0V89wb7ppA9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-41d1d62e-327c-4d47-b23d-495b135caf0a-0', tool_calls=[{'name': 'search_tool', 'args': {'query': 'FIFA World Cup 2022 winner'}, 'id': 'call_T6B8oGQRcm5Y964QCKQ9BO4F', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 22, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Search results for: FIFA World Cup 2022 winner', name='search_tool', id='a48d24bb-3583-47ec-8a36-1b402665c5bc', tool_call_id='call_T6B8oGQRcm5Y964QCKQ9BO4F'), AIMessage(content='The winner of the FIFA World Cup in 2022 was Argentina.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 97, 'total_tokens': 113, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BIW182IpsQw1gV0Q0am7C5KAl2ZS6', 'finish_reason': 'stop', 'logprobs': None}, id='run-9025751f-7c2f-4925-863d-c96d2a8b817e-0', usage_metadata={'input_tokens': 97, 'output_tokens': 16, 'total_tokens': 113, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the final message (last item in messages list)\n",
        "final_answer = response[\"messages\"][-1].content\n",
        "\n",
        "print(final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXSiglxExF1G",
        "outputId": "f3796752-3b3c-4f8e-b9e1-c45dde14a94f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The winner of the FIFA World Cup in 2022 was Argentina.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example 2\n",
        "inputs = {\"messages\":[(\"user\",\"What is Caldera and Mitre attack\")]}\n",
        "\n",
        "result = agent.invoke(inputs)\n",
        "\n",
        "#Get the final answer\n",
        "print(f\"Agent returned : {result['messages'][-1].content} \\n\")\n",
        "\n",
        "print(\"Step by Step execution : \")\n",
        "for message in result['messages']:\n",
        "    print(message.pretty_repr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHBT6muswoQB",
        "outputId": "3431504f-19a8-4fa1-809b-bf375083ed0b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent returned : I have found some information for you:\n",
            "\n",
            "1. **Caldera**: Caldera is a volcanic crater that forms after a volcanic eruption. It is typically a large, bowl-shaped depression at the top of a volcano. Calderas can vary in size and shape depending on the type of eruption that created them.\n",
            "\n",
            "2. **Mitre Attack**: MITRE ATT&CK is a knowledge base of adversary tactics and techniques based on real-world observations. It is a valuable resource for understanding and categorizing the tactics and techniques used by cyber adversaries during various stages of a cyber attack.\n",
            "\n",
            "Let me know if you need more information on either of these topics. \n",
            "\n",
            "Step by Step execution : \n",
            "================================ Human Message =================================\n",
            "\n",
            "What is Caldera and Mitre attack\n",
            "================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  search_tool (call_smAurnNq9ZQAjUJszbCXr77j)\n",
            " Call ID: call_smAurnNq9ZQAjUJszbCXr77j\n",
            "  Args:\n",
            "    query: Caldera\n",
            "  search_tool (call_zIjMDHrYPQ1hjDCWGWIpNi2l)\n",
            " Call ID: call_zIjMDHrYPQ1hjDCWGWIpNi2l\n",
            "  Args:\n",
            "    query: Mitre attack\n",
            "================================= Tool Message =================================\n",
            "Name: search_tool\n",
            "\n",
            "Search results for: Caldera\n",
            "================================= Tool Message =================================\n",
            "Name: search_tool\n",
            "\n",
            "Search results for: Mitre attack\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "I have found some information for you:\n",
            "\n",
            "1. **Caldera**: Caldera is a volcanic crater that forms after a volcanic eruption. It is typically a large, bowl-shaped depression at the top of a volcano. Calderas can vary in size and shape depending on the type of eruption that created them.\n",
            "\n",
            "2. **Mitre Attack**: MITRE ATT&CK is a knowledge base of adversary tactics and techniques based on real-world observations. It is a valuable resource for understanding and categorizing the tactics and techniques used by cyber adversaries during various stages of a cyber attack.\n",
            "\n",
            "Let me know if you need more information on either of these topics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the final message (last item in messages list)\n",
        "final_answer = result[\"messages\"][-1].content\n",
        "\n",
        "print(final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "safz9USPxQIb",
        "outputId": "25755545-df57-476a-fe21-5f5449df0f27"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have found some information for you:\n",
            "\n",
            "1. **Caldera**: Caldera is a volcanic crater that forms after a volcanic eruption. It is typically a large, bowl-shaped depression at the top of a volcano. Calderas can vary in size and shape depending on the type of eruption that created them.\n",
            "\n",
            "2. **Mitre Attack**: MITRE ATT&CK is a knowledge base of adversary tactics and techniques based on real-world observations. It is a valuable resource for understanding and categorizing the tactics and techniques used by cyber adversaries during various stages of a cyber attack.\n",
            "\n",
            "Let me know if you need more information on either of these topics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Typical agents in a Cyber AI PoC:\n",
        "\n",
        "Agent Name\tRole & Functionality\n",
        "üïµÔ∏è‚Äç‚ôÇÔ∏è Classifier Agent\tCategorizes incoming tickets or incidents\n",
        "üß† Reasoner Agent\tDetermines context, urgency, impact\n",
        "üõ† Action Planner Agent\tSuggests next actions (e.g., patch, escalate)\n",
        "üåê Search Agent\tAugments with external intelligence (CVE, blogs)\n",
        "üìù Summarizer Agent\tGenerates final action summary/report\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5VZ186ZpxVgy",
        "outputId": "da0c1a3e-98a8-4076-ad63-08cd8aad53fa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Typical agents in a Cyber AI PoC:\\n\\nAgent Name\\tRole & Functionality\\nüïµÔ∏è\\u200d‚ôÇÔ∏è Classifier Agent\\tCategorizes incoming tickets or incidents\\nüß† Reasoner Agent\\tDetermines context, urgency, impact\\nüõ† Action Planner Agent\\tSuggests next actions (e.g., patch, escalate)\\nüåê Search Agent\\tAugments with external intelligence (CVE, blogs)\\nüìù Summarizer Agent\\tGenerates final action summary/report'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"üß† Multi-Agent Mapping (LangGraph POC)\n",
        "Here‚Äôs how we can map this into a LangGraph multi-agent system:\n",
        "\n",
        "Agent\tRole\tTools Needed\n",
        "üì∞ CVE Ingestion Agent\tFetches and parses CVE feed\tRequests, JSON\n",
        "üßπ Normalizer Agent\tCleans and standardizes CVE fields\tRegex, pandas\n",
        "üìö Enrichment Agent\tAdds MITRE mappings, tags, severity scores\tCVE ‚Üí ATT&CK, scoring functions\n",
        "üß† LLM Context Agent\tUses OpenAI LLM to assess threat impact/context\tChatOpenAI, OpenAIEmbeddings\n",
        "üìä Summarizer Agent\tGenerates action insights / summary report\tLLM summarizer tool\n",
        "üåê External Search Agent\tLooks up CVEs, patches, etc. from external sources (optional)\tTool, LangChain Search\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "R0fUoPsazIDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Threat_Ingestion ‚Üí Normalizer ‚Üí Enrichment ‚Üí LLM_Context ‚Üí Summarizer\n",
        "                                       ‚Üò\n",
        "                                        ‚Üí ExternalSearch \"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "bx6TterDzb18",
        "outputId": "f623c0e3-a9e0-4bc6-91ae-d5ae8d8b298b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Threat_Ingestion ‚Üí Normalizer ‚Üí Enrichment ‚Üí LLM_Context ‚Üí Summarizer\\n                                       ‚Üò\\n                                        ‚Üí ExternalSearch '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "[CVE Ingestion] ‚Üí [Normalizer] ‚Üí [Enrichment] ‚Üí [LLM Context Analyzer] ‚Üí [Summarizer]\n",
        "We‚Äôll structure this using:\n",
        "\n",
        "langgraph.StateGraph\n",
        "\n",
        "create_react_agent for LLM-based nodes\n",
        "\n",
        "simple Python functions for deterministic logic (e.g. normalization)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "b2G8HHbuzmpY",
        "outputId": "dd3d6384-0ebc-4420-a203-2b6716d785ed"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n[CVE Ingestion] ‚Üí [Normalizer] ‚Üí [Enrichment] ‚Üí [LLM Context Analyzer] ‚Üí [Summarizer]\\nWe‚Äôll structure this using:\\n\\nlanggraph.StateGraph\\n\\ncreate_react_agent for LLM-based nodes\\n\\nsimple Python functions for deterministic logic (e.g. normalization)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "System Architecture\n",
        "We‚Äôll build 5 tools as modular agents:\n",
        "\n",
        "Tool (@tool)\tDescription\n",
        "cve_ingestion_tool\tLoads a sample CVE JSON (simulated or from file)\n",
        "normalizer_tool\tStandardizes CVE fields\n",
        "enrichment_tool\tMaps MITRE ATT&CK, adds severity\n",
        "llm_context_tool\tUses LLM to assess business/technical impact\n",
        "summary_tool\tGenerates a final action summary/report\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "kPuNNsWFz8N7",
        "outputId": "9a28c56e-2978-4cb9-cf23-a51772162814"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSystem Architecture\\nWe‚Äôll build 5 tools as modular agents:\\n\\nTool (@tool)\\tDescription\\ncve_ingestion_tool\\tLoads a sample CVE JSON (simulated or from file)\\nnormalizer_tool\\tStandardizes CVE fields\\nenrichment_tool\\tMaps MITRE ATT&CK, adds severity\\nllm_context_tool\\tUses LLM to assess business/technical impact\\nsummary_tool\\tGenerates a final action summary/report\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "we will create individual agents for each tool in LangGraph so you can view the graph structure, node-by-node, instead of having a single LLM ReAct agent calling tools.\n",
        "\n",
        "This approach is perfect for:\n",
        "\n",
        "üöÄ Fine-tuned control over execution\n",
        "\n",
        "üìà Visual graph view\n",
        "\n",
        "‚úÖ Debugging and tracing each stage\n",
        "\n",
        "üîÅ Future multi-turn interactions or state sharing\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "D7NEiXWM0dDp",
        "outputId": "85fc2364-574b-4801-e728-13bd11a3589c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwe will create individual agents for each tool in LangGraph so you can view the graph structure, node-by-node, instead of having a single LLM ReAct agent calling tools.\\n\\nThis approach is perfect for:\\n\\nüöÄ Fine-tuned control over execution\\n\\nüìà Visual graph view\\n\\n‚úÖ Debugging and tracing each stage\\n\\nüîÅ Future multi-turn interactions or state sharing\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" We will use stategraph for this:\n",
        "Graph Flow\n",
        "[CVE Ingestion Agent]\n",
        "        ‚Üì\n",
        "[Normalizer Agent]\n",
        "        ‚Üì\n",
        "[Enrichment Agent]\n",
        "        ‚Üì\n",
        "[LLM Context Agent]\n",
        "        ‚Üì\n",
        "[Summarizer Agent]\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "5Lt3j15g0x7K",
        "outputId": "bebcf395-effe-45ac-a5d0-50578307ac26"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' We will use stategraph for this:\\nGraph Flow\\n[CVE Ingestion Agent]\\n        ‚Üì\\n[Normalizer Agent]\\n        ‚Üì\\n[Enrichment Agent]\\n        ‚Üì\\n[LLM Context Agent]\\n        ‚Üì\\n[Summarizer Agent]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the shared state\n",
        "from typing import TypedDict, Optional\n",
        "\n",
        "class CyberState(TypedDict):\n",
        "    raw_cve_data: Optional[str]\n",
        "    normalized_data: Optional[dict]\n",
        "    enriched_data: Optional[dict]\n",
        "    context_analysis: Optional[str]\n",
        "    summary: Optional[str]\n"
      ],
      "metadata": {
        "id": "3P0pnqSE07J5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "2. Define each node (agent)\n",
        "Each of these can be either:\n",
        "\n",
        "A LangChain Runnable\n",
        "\n",
        "B function decorated as a node\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "76nPASYQ1A5A",
        "outputId": "5468cb39-380c-4005-9ca2-677fe950d27c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n2. Define each node (agent)\\nEach of these can be either:\\n\\nA LangChain Runnable\\n\\nA function decorated as a node\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent for Context Analysis\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "llm_context_agent = RunnableLambda(lambda state: {\n",
        "    \"context_analysis\": f\"Threat context for {state['enriched_data']['cve_id']} rated {state['enriched_data']['threat_score']}\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "R2hTWqW-1LNI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cve_ingestion_node(state):\n",
        "    sample_cve = {\n",
        "        \"id\": \"CVE-2023-0001\",\n",
        "        \"description\": \"Buffer overflow in XYZ component allows remote attackers to execute arbitrary code.\",\n",
        "        \"severity\": \"HIGH\",\n",
        "        \"product\": \"XYZ\",\n",
        "        \"version\": \"1.2.3\"\n",
        "    }\n",
        "    return {\"raw_cve_data\": json.dumps(sample_cve)}\n"
      ],
      "metadata": {
        "id": "NISXTqp_2_nu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizer Agent\n",
        "def normalizer_node(state):\n",
        "    import json\n",
        "    raw = json.loads(state[\"raw_cve_data\"])\n",
        "    return {\n",
        "        \"normalized_data\": {\n",
        "            \"cve_id\": raw[\"id\"],\n",
        "            \"desc\": raw[\"description\"],\n",
        "            \"severity\": raw[\"severity\"],\n",
        "            \"product\": raw[\"product\"],\n",
        "            \"version\": raw[\"version\"]\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "vyqdJDAF1aLH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizer_node(state):\n",
        "    data = json.loads(state[\"raw_cve_data\"])\n",
        "    normalized = {\n",
        "        \"cve_id\": data.get(\"id\"),\n",
        "        \"desc\": data.get(\"description\"),\n",
        "        \"severity\": data.get(\"severity\"),\n",
        "        \"product\": data.get(\"product\"),\n",
        "        \"version\": data.get(\"version\")\n",
        "    }\n",
        "    return {\"normalized_data\": normalized}\n"
      ],
      "metadata": {
        "id": "73PG9z5U3DhE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enrichment_tool_node(state):\n",
        "    cve = state[\"normalized_data\"]\n",
        "    enriched = {\n",
        "        **cve,\n",
        "        \"mitre_attack\": \"TA0001: Initial Access\",\n",
        "        \"threat_score\": 8.7  # This can be replaced with a real model/scoring API\n",
        "    }\n",
        "    return {\"enriched_data\": enriched}\n"
      ],
      "metadata": {
        "id": "q1o2k6R13Fzt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_context_agent(state):\n",
        "    cve = state[\"enriched_data\"]\n",
        "    analysis = (\n",
        "        f\"The vulnerability {cve['cve_id']} affects {cve['product']} version {cve['version']}. \"\n",
        "        f\"Description: {cve['desc']}. It is rated {cve['severity']} with a threat score of {cve['threat_score']}. \"\n",
        "        f\"Associated MITRE ATT&CK technique: {cve['mitre_attack']}.\"\n",
        "    )\n",
        "    return {\"context_analysis\": analysis}\n"
      ],
      "metadata": {
        "id": "hBjkpilv3Lvf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarizer_agent(state):\n",
        "    return {\n",
        "        \"summary\": f\"Summary Report:\\n{state['context_analysis']}\\nRecommendation: Patch immediately.\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "N6zDZV5O3PhY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangGraph Flow\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "builder = StateGraph(CyberState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"cve_ingestion\", lambda _: {\n",
        "    \"raw_cve_data\": '{\"id\":\"CVE-2023-0001\",\"description\":\"Buffer overflow...\",\"severity\":\"HIGH\",\"product\":\"XYZ\",\"version\":\"1.2.3\"}'\n",
        "})\n",
        "\n",
        "builder.add_node(\"normalizer\", normalizer_node)\n",
        "builder.add_node(\"enrichment\", enrichment_tool_node)\n",
        "builder.add_node(\"llm_context\", llm_context_agent)\n",
        "builder.add_node(\"summarizer\", summarizer_agent)\n",
        "\n",
        "# Set flow\n",
        "builder.set_entry_point(\"cve_ingestion\")\n",
        "builder.add_edge(\"cve_ingestion\", \"normalizer\")\n",
        "builder.add_edge(\"normalizer\", \"enrichment\")\n",
        "builder.add_edge(\"enrichment\", \"llm_context\")\n",
        "builder.add_edge(\"llm_context\", \"summarizer\")\n",
        "\n",
        "graph = builder.compile()\n"
      ],
      "metadata": {
        "id": "PL2rnFfU1guZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "MmbAZYHP2Xmj"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "final_output = graph.invoke({})\n",
        "print(final_output[\"summary\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHNrFIUx1u5H",
        "outputId": "f5f2d651-c178-4f06-fe02-56ca58a61eda"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Report:\n",
            "The vulnerability CVE-2023-0001 affects XYZ version 1.2.3. Description: Buffer overflow.... It is rated HIGH with a threat score of 8.7. Associated MITRE ATT&CK technique: TA0001: Initial Access.\n",
            "Recommendation: Patch immediately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "# graph.get_graph().draw()  # If using networkx + pygraphviz\n"
      ],
      "metadata": {
        "id": "kICwTG8r1zLS"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = graph.invoke({\"input\": \"Tell me about CVE-2023-34362\"})\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhTbiWLR11Di",
        "outputId": "5e6025be-b4c7-4e72-fd6b-7d0825f3fa07"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'raw_cve_data': '{\"id\":\"CVE-2023-0001\",\"description\":\"Buffer overflow...\",\"severity\":\"HIGH\",\"product\":\"XYZ\",\"version\":\"1.2.3\"}', 'normalized_data': {'cve_id': 'CVE-2023-0001', 'desc': 'Buffer overflow...', 'severity': 'HIGH', 'product': 'XYZ', 'version': '1.2.3'}, 'enriched_data': {'cve_id': 'CVE-2023-0001', 'desc': 'Buffer overflow...', 'severity': 'HIGH', 'product': 'XYZ', 'version': '1.2.3', 'mitre_attack': 'TA0001: Initial Access', 'threat_score': 8.7}, 'context_analysis': 'The vulnerability CVE-2023-0001 affects XYZ version 1.2.3. Description: Buffer overflow.... It is rated HIGH with a threat score of 8.7. Associated MITRE ATT&CK technique: TA0001: Initial Access.', 'summary': 'Summary Report:\\nThe vulnerability CVE-2023-0001 affects XYZ version 1.2.3. Description: Buffer overflow.... It is rated HIGH with a threat score of 8.7. Associated MITRE ATT&CK technique: TA0001: Initial Access.\\nRecommendation: Patch immediately.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quering agents individually\n",
        "def normalizer_node(state):\n",
        "    data = json.loads(state[\"raw_cve_data\"])\n",
        "    normalized = {\n",
        "        \"cve_id\": data.get(\"id\"),\n",
        "        \"desc\": data.get(\"description\"),\n",
        "        \"severity\": data.get(\"severity\"),\n",
        "        \"product\": data.get(\"product\"),\n",
        "        \"version\": data.get(\"version\")\n",
        "    }\n",
        "    return {\"normalized_data\": normalized}\n",
        "# def normalizer_node(state):\n",
        "#     input_text = state[\"input\"]\n",
        "#     # normalize input here\n",
        "#     return {\"normalized_input\": input_text.lower()}\n",
        "# Manually test the normalizer\n",
        "output = normalizer_node({\"input\": \"Tell me about CVE-2023-34362\"})\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "gTBVpZi28eMO",
        "outputId": "4c13e683-ecd1-4a22-e028-8cecd0ac8458"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'raw_cve_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-11a7f65b0746>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     return {\"normalized_input\": input_text.lower()}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Manually test the normalizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Tell me about CVE-2023-34362\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-11a7f65b0746>\u001b[0m in \u001b[0;36mnormalizer_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Quering agents individually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalizer_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"raw_cve_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     normalized = {\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"cve_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'raw_cve_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent Chaining"
      ],
      "metadata": {
        "id": "ooeBwjG39jRk"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = {\"input\": \"Tell me about CVE-2023-34362\", \"raw_cve_data\": '{\"id\":\"CVE-2023-34362\",\"description\":\"Buffer overflow...\",\"severity\":\"HIGH\",\"product\":\"XYZ\",\"version\":\"1.2.3\"}'} # Added raw_cve_data to the state dictionary\n",
        "\n",
        "\n",
        "step1 = normalizer_node(state)\n",
        "step2 = enrichment_tool_node({**state, **step1}) # changed enrichment_node to enrichment_tool_node\n",
        "step3 = llm_context_agent({**state, **step1, **step2}) #changed llm_context_node to llm_context_agent\n",
        "step4 = summarizer_agent({**state, **step1, **step2, **step3}) #changed summarizer_node to summarizer_agent\n",
        "\n",
        "print(step4[\"summary\"])  # Final output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2HhJw0a9LHx",
        "outputId": "ba76e95e-fc13-49b0-b5a4-496665accfb2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Report:\n",
            "The vulnerability CVE-2023-34362 affects XYZ version 1.2.3. Description: Buffer overflow.... It is rated HIGH with a threat score of 8.7. Associated MITRE ATT&CK technique: TA0001: Initial Access.\n",
            "Recommendation: Patch immediately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sudo apt-get install graphviz\n",
        "# !pip install pygraphviz\n"
      ],
      "metadata": {
        "id": "FlcO1_ke33Yu"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grandalf\n",
        "print(graph.get_graph().draw_ascii())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9zxDPWJ5Yy_",
        "outputId": "05d567e1-6fd1-4e2f-d8ce-5052ed1fa43c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grandalf\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.2.3)\n",
            "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: grandalf\n",
            "Successfully installed grandalf-0.8\n",
            "  +-----------+    \n",
            "  | __start__ |    \n",
            "  +-----------+    \n",
            "        *          \n",
            "        *          \n",
            "        *          \n",
            "+---------------+  \n",
            "| cve_ingestion |  \n",
            "+---------------+  \n",
            "        *          \n",
            "        *          \n",
            "        *          \n",
            "  +------------+   \n",
            "  | normalizer |   \n",
            "  +------------+   \n",
            "        *          \n",
            "        *          \n",
            "        *          \n",
            "  +------------+   \n",
            "  | enrichment |   \n",
            "  +------------+   \n",
            "        *          \n",
            "        *          \n",
            "        *          \n",
            " +-------------+   \n",
            " | llm_context |   \n",
            " +-------------+   \n",
            "        *          \n",
            "        *          \n",
            "        *          \n",
            "  +------------+   \n",
            "  | summarizer |   \n",
            "  +------------+   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langgraph\n",
        "dir(langgraph) # Check available modules/functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roJCEIBH6XfK",
        "outputId": "ac1ed143-f7e3-409b-dc43-f65255ba9b35"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_api',\n",
              " 'channels',\n",
              " 'checkpoint',\n",
              " 'config',\n",
              " 'constants',\n",
              " 'errors',\n",
              " 'graph',\n",
              " 'managed',\n",
              " 'prebuilt',\n",
              " 'pregel',\n",
              " 'store',\n",
              " 'types',\n",
              " 'utils']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwu4TaGg6z3Q"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from IPython.display import Image, display\n",
        "\n",
        "# display(Image(graph.get_graph().draw_ascii()))\n"
      ],
      "metadata": {
        "id": "Ve8psUmt5QrK"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"dynamic Logic Based on LLM? llm_context_node to decide the next agent (multi-path)\"\"\""
      ],
      "metadata": {
        "id": "dZc1D1gb3vZ4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if \"ransomware\" in llm_analysis.lower():\n",
        "#     next_node = ransomware_agent\n",
        "# else:\n",
        "#     next_node = generic_explanation_agent\n"
      ],
      "metadata": {
        "id": "qEAWFEC83rQy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# branching can be handled inside LangGraph using:"
      ],
      "metadata": {
        "id": "xr7EQxzzTR5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder.add_conditional_edges(\"llm_context\", lambda state: state[\"topic\"], {\n",
        "    \"ransomware\": \"ransomware_agent\",\n",
        "    \"default\": \"generic_explanation_agent\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "h4MAKV4QTR7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHR_5dl9ThN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal\tHow to Do It\n",
        "Query agent individually\tCall the node like a Python function\n",
        "Chain agents manually\tFeed outputs as state dict to next\n",
        "Auto-branch with logic\tUse add_conditional_edges() in LangGraph\n",
        "Debug flows\tUse prints / logs in each node"
      ],
      "metadata": {
        "id": "j3ZQQOsIThc5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxpbZZ9ITi0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}